"""
Service pour g√©n√©rer des explications √©motionnelles en fran√ßais
IMPORTANT: Ce service ne g√©n√®re JAMAIS de textes sacr√©s (Quran, Hadith, Douaa)
Les textes sacr√©s viennent UNIQUEMENT de MongoDB.
Le LLM g√©n√®re UNIQUEMENT une explication courte (2-3 phrases) expliquant pourquoi le douaa aide √©motionnellement.
R√¥le du LLM: Accompagnateur √©motionnel, PAS autorit√© religieuse.
"""
import os
import re
from typing import Optional

import requests
from dotenv import load_dotenv

# Charger les variables d'environnement depuis .env
load_dotenv()

# Configuration API Hugging Face (gratuite mais limit√©e)
ENABLE_LLM = os.getenv("ENABLE_LLM_EXPLANATION", "true").lower() == "true"

# OpenRouter Configuration (RECOMMENDED)
OPENROUTER_API_KEY = os.getenv("OPENROUTER_API_KEY", "").strip()
OPENROUTER_MODEL = os.getenv("OPENROUTER_MODEL", "mistralai/mistral-7b-instruct:free")
OPENROUTER_API_URL = "https://openrouter.ai/api/v1/chat/completions"

# Hugging Face Configuration (fallback)
HF_MODEL_NAME = os.getenv("HF_MODEL_NAME", "mistralai/Mistral-7B-Instruct-v0.1")
# Use the serverless inference endpoint with correct format
HF_API_URL = os.getenv("HF_API_URL", f"https://api-inference.huggingface.co/models/{HF_MODEL_NAME}")
HF_TOKEN = os.getenv("HF_TOKEN", "").strip()
HF_TIMEOUT = float(os.getenv("HF_TIMEOUT_SECONDS", "25"))

# Log de configuration au chargement du module
print(f"[EXPLANATION_SERVICE] Configuration LLM:")
print(f"  - ENABLE_LLM: {ENABLE_LLM}")
if OPENROUTER_API_KEY:
    print(f"  - Provider: OpenRouter ‚úì")
    print(f"  - Model: {OPENROUTER_MODEL}")
else:
    print(f"  - Provider: Hugging Face")
    print(f"  - HF_MODEL_NAME: {HF_MODEL_NAME}")
    print(f"  - HF_TOKEN: {'‚úì Configur√©' if HF_TOKEN else '‚úó Non configur√©'}")
print(f"  - HF_TIMEOUT: {HF_TIMEOUT}s")

# Explications pr√©-d√©finies en fran√ßais comme fallback (am√©lior√©es pour plus de profondeur spirituelle)
FRENCH_EXPLANATIONS = {
    "happy": "Ce douaa vous aide √† exprimer votre gratitude envers Allah et √† maintenir cette sensation de paix int√©rieure. Il renforce votre connexion spirituelle, vous rappelle que le bonheur v√©ritable vient de la foi, et vous permet de savourer pleinement ce moment de joie tout en restant humble.",
    "sad": "Ce douaa vous apporte r√©confort et apaisement dans les moments difficiles. Il vous rappelle que vous n'√™tes jamais seul, qu'Allah est toujours avec vous, et que la patience (sabr) et la foi peuvent transformer la tristesse en force int√©rieure et en rapprochement spirituel.",
    "angry": "Ce douaa vous aide √† calmer votre col√®re et √† retrouver votre s√©r√©nit√©. Il vous guide vers la patience, le pardon et la compr√©hension, transformant les √©motions n√©gatives en √©nergie positive. La ma√Ætrise de soi dans la col√®re est une forme de force spirituelle.",
    "fear": "Ce douaa vous apporte protection divine et courage face √† vos peurs. Il renforce votre confiance en Allah, vous rappelle que vous avez la force int√©rieure n√©cessaire pour surmonter vos craintes, et que la foi est le meilleur rem√®de contre l'anxi√©t√©.",
    "neutral": "Ce douaa vous aide √† maintenir votre √©quilibre √©motionnel et votre paix int√©rieure. Il renforce votre connexion spirituelle avec Allah, vous permet de rester centr√© dans le moment pr√©sent, et cultive un √©tat de s√©r√©nit√© et de gratitude constante.",
    "surprised": "Ce douaa vous aide √† accueillir l'inattendu avec s√©r√©nit√© et gratitude. Il vous rappelle que tout ce qui arrive est par la volont√© d'Allah, et vous guide pour transformer la surprise en opportunit√© de croissance spirituelle et de renforcement de votre foi.",
    "anxious": "Ce douaa vous apporte calme et tranquillit√© dans les moments d'anxi√©t√©. Il vous aide √† l√¢cher prise, √† faire confiance en Allah, et √† vous rappeler que Lui seul contr√¥le l'avenir. La r√©citation r√©guli√®re r√©duit le stress et apporte la paix du c≈ìur.",
    "excited": "Ce douaa vous aide √† canaliser votre enthousiasme de mani√®re positive et spirituelle. Il vous rappelle de rester humble dans la joie, de partager votre bonheur avec gratitude, et de diriger votre √©nergie vers des actions qui plaisent √† Allah.",
    "lonely": "Ce douaa vous rappelle que vous √™tes toujours accompagn√© spirituellement par Allah. Il vous apporte r√©confort, vous aide √† ressentir la pr√©sence divine dans votre vie, et transforme la solitude en moment privil√©gi√© de connexion spirituelle et de m√©ditation.",
    "grateful": "Ce douaa renforce votre sentiment de gratitude envers Allah et vous aide √† exprimer votre reconnaissance pour Ses innombrables bienfaits. Il vous permet de savourer pleinement les b√©n√©dictions de votre vie et vous rappelle que la gratitude attire davantage de b√©n√©dictions.",
    "hopeful": "Ce douaa renforce votre espoir et votre foi en l'avenir. Il vous rappelle qu'Allah a un plan pour chacun, que chaque jour apporte de nouvelles possibilit√©s, et que la patience et la confiance en Lui portent toujours leurs fruits."
}

EMOTION_FRENCH = {
    "happy": "joie",
    "sad": "tristesse",
    "angry": "col√®re",
    "fear": "peur",
    "neutral": "calme",
    "surprised": "surprise",
    "anxious": "anxi√©t√©",
    "excited": "excitation",
    "lonely": "solitude",
    "grateful": "gratitude",
    "hopeful": "espoir",
}


def _confidence_percent(confidence: Optional[float]) -> Optional[float]:
    if confidence is None:
        return None
    return confidence * 100 if confidence <= 1 else confidence


def _build_prompt(emotion: str, confidence: Optional[float], douaa: str) -> str:
    emotion_fr = EMOTION_FRENCH.get(emotion.lower(), "cette √©motion")
    conf_pct = _confidence_percent(confidence)
    conf_text = f"{conf_pct:.1f}%" if conf_pct is not None else "non pr√©cis√©e"
    
    # D√©terminer le ton selon la confiance
    if conf_pct is None or conf_pct < 55:
        ton_instruction = "prudent et nuanc√©"
    elif conf_pct < 80:
        ton_instruction = "affirm√© mais nuanc√©"
    else:
        ton_instruction = "confiant"
    
    return f"""G√©n√®re une explication √©motionnelle courte (2-3 phrases) en fran√ßais uniquement.

√âmotion d√©tect√©e: {emotion_fr} (confiance: {conf_text})
Ton: {ton_instruction}

Instructions:
- Explique comment cette invocation spirituelle peut aider avec cette √©motion
- Ne cite PAS le douaa, ne g√©n√®re AUCUN texte sacr√©
- Utilise un langage naturel et chaleureux
- R√©ponds UNIQUEMENT avec l'explication, sans pr√©ambule ni instruction

Explication:"""


def _call_hf_api(prompt: str, retry_on_503: bool = True) -> str:
    """
    Appelle l'API OpenRouter ou Hugging Face pour g√©n√©rer du texte.
    
    Args:
        prompt: Le prompt √† envoyer au mod√®le
        retry_on_503: Si True, attendre et r√©essayer si le mod√®le est en cours de chargement (503)
    
    Returns:
        str: Le texte g√©n√©r√© par le mod√®le
    """
    import time
    
    # Try OpenRouter first if configured
    if OPENROUTER_API_KEY:
        return _call_openrouter_api(prompt, retry_on_503)
    
    # Fallback to Hugging Face
    return _call_hf_api_direct(prompt, retry_on_503)


def _call_openrouter_api(prompt: str, retry_on_503: bool = True) -> str:
    """Appelle l'API OpenRouter."""
    import time
    
    headers = {
        "Authorization": f"Bearer {OPENROUTER_API_KEY}",
        "Content-Type": "application/json",
    }
    
    payload = {
        "model": OPENROUTER_MODEL,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": 0.7,
        "top_p": 0.9,
        "max_tokens": 150,
    }
    
    max_retries = 2 if retry_on_503 else 0
    retry_delay = 10
    
    for attempt in range(max_retries + 1):
        try:
            print(f"[DEBUG] Appel OpenRouter API (tentative {attempt + 1}/{max_retries + 1})...")
            resp = requests.post(
                OPENROUTER_API_URL,
                headers=headers,
                json=payload,
                timeout=HF_TIMEOUT,
            )
            
            if resp.status_code == 503:
                if retry_on_503 and attempt < max_retries:
                    print(f"[INFO] Service indisponible. Attente de {retry_delay}s...")
                    time.sleep(retry_delay)
                    continue
                else:
                    raise RuntimeError(f"OpenRouter: Service indisponible (503)")
            elif resp.status_code == 401:
                raise RuntimeError(f"OpenRouter: Erreur d'authentification (401). V√©rifiez OPENROUTER_API_KEY.")
            elif resp.status_code != 200:
                error_text = resp.text[:300] if resp.text else "Unknown error"
                raise RuntimeError(f"OpenRouter error {resp.status_code}: {error_text}")
            
            break
            
        except requests.exceptions.Timeout:
            raise RuntimeError(f"Timeout OpenRouter (>{HF_TIMEOUT}s)")
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"Erreur r√©seau OpenRouter: {str(e)}")
    
    data = resp.json()
    
    # OpenRouter uses standard OpenAI format
    if "choices" in data and data["choices"]:
        text = data["choices"][0].get("message", {}).get("content", "").strip()
    elif "error" in data:
        raise RuntimeError(f"OpenRouter error: {data['error'].get('message', 'Unknown error')}")
    else:
        raise RuntimeError(f"OpenRouter unexpected response: {str(data)[:300]}")
    
    return text


def _call_hf_api_direct(prompt: str, retry_on_503: bool = True) -> str:
    """Appelle l'API Hugging Face directement."""
    import time
    
    headers = {"Authorization": f"Bearer {HF_TOKEN}"} if HF_TOKEN else {}
    payload = {
        "inputs": prompt,
        "parameters": {
            "max_new_tokens": 150,
            "temperature": 0.7,
            "top_p": 0.9,
        },
    }
    
    max_retries = 2 if retry_on_503 else 0
    retry_delay = 10  # secondes
    
    for attempt in range(max_retries + 1):
        try:
            print(f"[DEBUG] Appel API Hugging Face (tentative {attempt + 1}/{max_retries + 1})...")
            resp = requests.post(
                HF_API_URL,
                headers=headers,
                json=payload,
                timeout=HF_TIMEOUT,
            )
            
            # G√©rer les erreurs sp√©cifiques de l'API Hugging Face
            if resp.status_code == 503:
                # Le mod√®le est en train de se charger
                try:
                    error_data = resp.json()
                    error_msg = error_data.get("error", "Model is loading")
                    estimated_time = error_data.get("estimated_time", None)
                except:
                    error_msg = "Model is loading"
                    estimated_time = None
                
                if retry_on_503 and attempt < max_retries:
                    wait_time = estimated_time if estimated_time else retry_delay
                    print(f"[INFO] Mod√®le en cours de chargement. Attente de {wait_time}s avant r√©essai...")
                    time.sleep(wait_time)
                    continue
                else:
                    raise RuntimeError(f"HF API: Mod√®le en cours de chargement. {error_msg}")
            elif resp.status_code == 401:
                error_text = resp.text[:300] if resp.text else "Unauthorized"
                raise RuntimeError(f"HF API: Erreur d'authentification (401). V√©rifiez votre token. {error_text}")
            elif resp.status_code == 410:
                error_text = resp.text[:300] if resp.text else "API deprecated"
                raise RuntimeError(f"HF API: Endpoint deprecated (410). Mettez √† jour HF_API_URL. {error_text}")
            elif resp.status_code != 200:
                error_text = resp.text[:300] if resp.text else "Unknown error"
                raise RuntimeError(f"HF API error {resp.status_code}: {error_text}")
            
            # Succ√®s
            break
            
        except requests.exceptions.Timeout:
            raise RuntimeError(f"Timeout lors de l'appel √† l'API Hugging Face (>{HF_TIMEOUT}s)")
        except requests.exceptions.RequestException as e:
            raise RuntimeError(f"Erreur r√©seau lors de l'appel √† l'API Hugging Face: {str(e)}")

    data = resp.json()
    
    # G√©rer diff√©rents formats de r√©ponse
    if isinstance(data, list) and data:
        text = data[0].get("generated_text", "")
        # Extraire seulement la partie g√©n√©r√©e (sans le prompt)
        if prompt in text:
            text = text.replace(prompt, "").strip()
    elif isinstance(data, dict):
        if "generated_text" in data:
            text = data["generated_text"]
            # Extraire seulement la partie g√©n√©r√©e (sans le prompt)
            if prompt in text:
                text = text.replace(prompt, "").strip()
        elif "error" in data:
            raise RuntimeError(f"HF API error: {data['error']}")
        else:
            raise RuntimeError(f"HF API unexpected payload: {str(data)[:300]}")
    else:
        raise RuntimeError(f"HF API unexpected payload: {str(data)[:300]}")

    return text.strip()


def _normalize_text(explanation: str) -> str:
    if not explanation:
        return ""

    sentences = []
    for sep in [".", "!", "?", "\n"]:
        if sep in explanation:
            sentences = [s.strip() for s in explanation.split(sep) if s.strip()]
            break

    if not sentences:
        sentences = [explanation.strip()] if explanation.strip() else []

    if sentences:
        explanation = ". ".join(sentences[:3]).strip()
        if explanation and not explanation.endswith((".", "!", "?")):
            explanation += "."
    else:
        explanation = ""

    return explanation


def _is_invalid(explanation: str) -> tuple[bool, list[str]]:
    reasons = []
    exp_lower = explanation.lower()

    if len(explanation.strip()) < 20:
        reasons.append("trop court")
    if not explanation.strip():
        reasons.append("vide")

    has_arabic = bool(re.search(r"[\u0600-\u06FF]", explanation))
    if has_arabic:
        reasons.append("texte arabe d√©tect√©")

    verse_markers = ["sourate", "ayah", "verset", "quran", "coran", "ÿ≥Ÿàÿ±ÿ©", "ÿ¢Ÿäÿ©"]
    if any(marker in exp_lower for marker in verse_markers):
        reasons.append("marqueurs de versets d√©tect√©s")

    instruction_words = [
        "explique",
        "parle",
        "r√©ponds",
        "uniquement",
        "fran√ßais",
        "phrases",
        "court",
        "simplement",
        "comment",
        "une personne ressent",
    ]
    if any(exp_lower.strip().startswith(word) for word in instruction_words):
        reasons.append("d√©bute par instruction")

    instruction_count = sum(1 for word in instruction_words if word in exp_lower)
    if instruction_count >= 3:
        reasons.append("instructions r√©p√©t√©es")

    if "une personne ressent de la" in exp_lower:
        reasons.append("prompt r√©p√©t√©")

    return len(reasons) > 0, reasons


def _dynamic_fallback(emotion: str, confidence: Optional[float]) -> str:
    base = FRENCH_EXPLANATIONS.get(emotion.lower(), FRENCH_EXPLANATIONS["neutral"])
    emotion_fr = EMOTION_FRENCH.get(emotion.lower(), emotion.lower())
    conf_pct = _confidence_percent(confidence)
    conf_text = f"{conf_pct:.1f}%" if conf_pct is not None else "confiance non pr√©cis√©e"

    if conf_pct is None:
        ton = "prudent"
        signal = "non pr√©cis√©"
    elif conf_pct < 55:
        ton = "prudent"
        signal = "mod√©r√©"
    elif conf_pct < 80:
        ton = "affirm√© mais nuanc√©"
        signal = "assez clair"
    else:
        ton = "confiant"
        signal = "net"

    return (
        f"Je per√ßois surtout de la {emotion_fr} ({conf_text}). "
        f"Le ton reste {ton} car le signal est {signal}. "
        f"{base}"
    )


def get_fallback_explanation(emotion: str, confidence: Optional[float] = None) -> str:
    """
    Fonction publique pour obtenir une explication de fallback avec la confiance.
    
    Args:
        emotion: L'√©motion d√©tect√©e
        confidence: Score de confiance du mod√®le d'√©motion
    
    Returns:
        str: Explication de fallback en fran√ßais
    """
    return _dynamic_fallback(emotion, confidence)


def generate_explanation(emotion: str, douaa: str, confidence: Optional[float] = None) -> tuple[str, str]:
    """
    G√©n√®re une explication courte en fran√ßais expliquant pourquoi le Douaa aide avec l'√©motion.
    
    R√àGLES IMPORTANTES:
    - Ne JAMAIS g√©n√©rer de textes sacr√©s (Quran, Hadith, Douaa) - ils viennent de MongoDB
    - G√©n√©rer UNIQUEMENT une explication √©motionnelle/psychologique (2-3 phrases)
    - R√©ponse en FRAN√áAIS uniquement
    - R√¥le: Accompagnateur √©motionnel, PAS autorit√© religieuse
    
    Args:
        emotion: L'√©motion d√©tect√©e (ex: "happy", "sad", "angry")
        douaa: Le douaa s√©lectionn√© depuis la base de donn√©es (pour contexte uniquement)
        confidence: Score de confiance du mod√®le d'√©motion (0-100 ou 0-1)
    
    Returns:
        tuple[str, str]: (explication en fran√ßais, source) o√π source est "llm" ou "static"
    """
    if not ENABLE_LLM:
        print(f"[INFO] LLM d√©sactiv√© (ENABLE_LLM_EXPLANATION=false). Utilisation du fallback statique.")
        explanation = _dynamic_fallback(emotion, confidence)
        return explanation, "static"

    print(f"[INFO] Tentative de g√©n√©ration LLM pour √©motion: {emotion}, confiance: {confidence}")
    
    try:
        prompt = _build_prompt(emotion, confidence, douaa)
        print(f"[DEBUG] Prompt construit: {prompt[:100]}...")
        
        raw_text = _call_hf_api(prompt)
        print(f"[DEBUG] R√©ponse brute LLM: '{raw_text[:150]}...'")
        
        explanation = _normalize_text(raw_text)
        print(f"[DEBUG] Explication normalis√©e: '{explanation[:150]}...'")

        is_invalid, reasons = _is_invalid(explanation)
        if is_invalid:
            print(f"[WARN] R√©ponse LLM rejet√©e ({', '.join(reasons)}). Utilisation du fallback dynamique.")
            print(f"   R√©ponse LLM compl√®te: '{explanation}'")
            explanation = _dynamic_fallback(emotion, confidence)
            return explanation, "static"

        print(f"[OK] Explication LLM g√©n√©r√©e avec succ√®s: '{explanation[:80]}...'")
        return explanation, "llm"

    except RuntimeError as e:
        error_msg = str(e)
        print(f"[WARN] Erreur API Hugging Face: {error_msg}")
        if "401" in error_msg or "authentification" in error_msg.lower():
            print(f"[ERROR] ‚ö†Ô∏è  Probl√®me d'authentification! V√©rifiez que HF_TOKEN est correct dans .env")
            print(f"[INFO] üí° Alternative: Utilisez OpenRouter pour une API plus fiable")
        elif "503" in error_msg or "chargement" in error_msg.lower():
            print(f"[INFO] Le mod√®le est en cours de chargement. R√©essayez dans quelques secondes.")
        elif "410" in error_msg or "deprecated" in error_msg.lower():
            print(f"[ERROR] ‚ö†Ô∏è  L'endpoint Hugging Face a chang√©. V√©rifiez HF_API_URL dans .env")
            print(f"[INFO] üí° Alternative: Utilisez https://router.huggingface.co ou OpenRouter")
        else:
            print(f"[WARN] Erreur LLM: {error_msg}")
        explanation = _dynamic_fallback(emotion, confidence)
        return explanation, "static"
    except Exception as e:
        print(f"[WARN] Erreur inattendue lors de la g√©n√©ration de l'explication LLM: {type(e).__name__}: {e}")
        import traceback
        print(f"[DEBUG] Traceback complet:\n{traceback.format_exc()}")
        explanation = _dynamic_fallback(emotion, confidence)
        return explanation, "static"

